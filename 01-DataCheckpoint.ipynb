{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Evan Honggo Widjojo: Conceptualization, Methodology, Data curation\n",
    "- Ahmad Bin Feizal: Background research, Data curation\n",
    "- Nicholas Chan: Data curation, Writing - review & editing, Project administration\n",
    "- Fadi Gorgees: Background research, Methodology, Data curation\n",
    "- Neenos Yaldiko: Project administration, Data curation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are different styles of social media use, passive consumption versus active interaction, associated with wellbeing outcomes among adults aged 18+? We define passive consumption as behaviors like time spent browsing content and viewing posts or short form videos, and active interaction as behaviors like posting, commenting, liking, and direct messaging. Our primary wellbeing outcomes are self reported stress and self reported happiness, and we will also examine sleep related and basic physical health indicators when available. To reduce confounding in this observational study, we will control for demographic factors, socioeconomic status, and lifestyle variables such as physical activity and work hours. We will use regression based statistical inference to estimate associations and will avoid causal claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media uses are now a major component of everyday life. Instagram, Facebook, TikTok and Snapchat have accrued daily engagement of the majority of adults. As social media use has grown, research has shifted towards focusing on the manner in which individuals engage with it. For this study, we are using a widely adopted distinction which identifies active interaction as including posting content, commenting, liking, and direct messaging. On the other hand, passive consumption includes browsing feeds or watching short-term videos Our initial research suggests that these usage styles may influence different psychological mechanisms with passive use often linked to social comparison and envy, while active use may have higher perceived support and social connectedness. However, associations with other wellbeing outcomes including stress, happiness, sleep quality, and physical health remain mixed and motivates further investigation.\n",
    "\n",
    "One prior influential effort in this study is the Social Media Activity Questionnaire (SMAQ), which surveyed 1,230 participants derived from Facebook Activity Questionnaire. This study by Ozimek, Brailovskaia and Bierhoff separated actions identified as active and passive engagements with a rating scale from 1 to 5.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) With the application of exploratory factor analysis (EFA) to identify behavioral dimensions, outcomes regarding mental health were assessed using established scales. These include Bergen Social Media Addiction Scale, Fear of Missing Out (FoMO) scale, and the Depression Anxiety Stress Scales (DASS). In contrast to our project, this study focused on negative mental health indicators, rather than trying to estimate well being directly which remains  our priority. Research outcome displayed stronger association between active use depression, anxiety and stress, while passive was more strongly associated with problematic behavioral tendencies like addiction and FoMO. Researchers' opinions attributed these tendencies to upwards social comparison and envy enabled by consumed contents.\n",
    "\n",
    "One notable limitation to the SMAQ study was the disproportionate sample of mostly young and females, which limits generalizability to the broader population. Other than that, the data set was limited to Facebook users and geographically restricted to the Ruhr region of Germany. This makes it difficult to extrapolate any observations to older adults, different cultural contexts, and our specific social media of choice, Instagram.\n",
    "\n",
    " Another referenced perspective is provided by the study “Are active and passive social media use related to mental health, wellbeing, and social support outcomes?”. This meta-analysis synthesizes findings from 141 quantitative studies which studies correlations between social media use styles and 13 mental health and wellbeing outcomes. Using pooled effect sizes, Godard and Holtzman report that neither active nor passive use strongly predicts well being on average, with most effects being minute.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) Active use has modest association with perceived social support and wellbeing, but also with slightly higher anxiety. Passive use showed overall weak associations but were more linked to worse emotional outcomes in general contexts. Crucially, this study highlights that demographic characteristics and contextual moderators, such as age and usage setting, have more substantial influence on outcomes. These findings show the importance of controlling for confounding factors rather than simplistic narratives like “active is good, passive is bad” which becomes a focus in guiding our project.\n",
    "\n",
    " A study that heavily grounded age as contextual moderator is Underwood’s expanded literature review which is specific to adolescents aged 10-19. Reviewing 16 peer-reviewed studies gathered from MEDLINE and PubMed via keyword search, the literature review concludes that both active and passive social media has positive association with negative mental health outcomes in adolescents.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) While evidence was insufficient to conclude that one style is categorically more harmful, this study shows the repeated importance of grounding research by age as observations of effects varied across different stages of adolescence. Our current study aims to control moderating factors by narrowing our analysis to Instagram usage among adults aged 18+. We target to examine both positive and negative wellbeing outcomes stretching beyond happiness and stress to include physical health factors like sleep and physical health while explicitly accounting for demographic, socioeconomic, and lifestyle confounders.\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1)  Ozimek, P., Brailovskaia, J., Bierhoff, H-W. (2023) Active and passive behavior in social media: Validating the Social Media Activity Questionnaire (SMAQ), Telematics and Informatics Reports, Volume 10, 100048, ISSN 2772-5030, https://doi.org/10.1016/j.teler.2023.100048\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Godard, R., Holtzman, S. (2024). Are active and passive social media use related to mental health, wellbeing, and social support outcomes? A meta-analysis of 141 studies, Journal of Computer-Mediated Communication, Volume 29, Issue 1, January 2024, zmad055, https://doi.org/10.1093/jcmc/zmad055\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3)  Underwood, L. (2024). Difference Between the Impact of Active Social Media Use and Passive Social Media Use on Adolescent Mental Health: An Expanded Literature Review. The Eleanor Mann School of Nursing Undergraduate Honors. https://scholarworks.uark.edu/nursuht/211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that among adults aged 18+, higher passive social media consumption will be associated with higher self reported stress and lower self reported happiness, while higher active interaction will be associated with lower stress and higher happiness. This is because passive browsing tends to increase social comparison and rumination, whereas active interaction is more likely to involve social connection and support, which can buffer stress and improve mood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Datasets Information:\n",
    "- Dataset #1\n",
    "  - Dataset Name: Instagram Usage Lifestyle Dataset (instagram_usage_lifestyle.csv)\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/sadiajavedd/social-media-user-activity-dataset\n",
    "  - Number of observations: 1,547,896 raw rows; 1,401,638 rows after applying the age 18+ filter\n",
    "  - Number of variables: 58 raw columns; 14 columns in our processed analysis table for Dataset #1\n",
    "  - Description of the variables most relevant to this project: We use time_on_feed_per_day as our passive-use proxy (minutes/day), posts_created_per_week as our active-use proxy (posts/week), perceived_stress_score as the stress outcome, and self_reported_happiness as the happiness outcome. We retain controls for confounding: age, gender, country, urban_rural, income_level, employment_status, education_level, exercise_hours_per_week, sleep_hours_per_night, and weekly_work_hours\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project: The dataset is observational and treated as cross-sectional in our checkpoint, so we cannot make causal claims. Our initial active/passive operationalization uses one variable for each style, which may not fully capture the full behavior spectrum; we may expand to composite measures in later analysis. The data are also unusually clean (near-zero missingness across many fields), which may indicate synthetic or heavily processed construction and can limit external validity. Finally, despite using controls, unmeasured confounding can still bias estimated associations.\n",
    "\n",
    "- Dataset #2\n",
    "  - Dataset Name: **Mental Health & Social Media Balance Dataset**\n",
    "  - Link to the dataset: `https://www.kaggle.com/datasets/prince7489/mental-health-and-social-media-balance-dataset?`\n",
    "  - Number of observations: 500\n",
    "  - Number of variables: 10\n",
    "  - Description of the variables most relevant to this project:\n",
    "    - Daily Screen Time (Hours): Average hours per day spent on social media. This is our primary variable of interest.\n",
    "    - Sleep Quality (1–10 scale): Self reported sleep quality, where higher scores indicate better perceived sleep.\n",
    "    - Stress Level (1–10 scale): Self reported stress level, where higher values indicate higher stress levels.\n",
    "    - Happiness Index (1–10 scale): Self reported happiness, where higher scores indicate greater subjective well being.\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project:\n",
    "    - Lacks data to distinguish whether social media use was passive consumption or active interaction.\n",
    "    - Most data is self reported so there may be biases or inaccurately reported data.\n",
    "- Dataset #3  \n",
    "  - Dataset Name: **Social Media Usage and Emotional Well-Being**  \n",
    "  - Link to the dataset: `https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being`  \n",
    "  - Number of observations: Uses 3 Observations:  \n",
    "    - train.csv: 1001 rows  \n",
    "    - val.csv: 145 rows  \n",
    "    - test.csv: 103 rows  \n",
    "  - Number of variables: **10** columns  \n",
    "\n",
    "  - Description of the variables most relevant to this project:  \n",
    "    This dataset is basically “social media behavior metrics” + a label for emotion. The main columns are:  \n",
    "\n",
    "    - User_ID: unique user identifier  \n",
    "    - Age (years) and Gender: basic demographics  \n",
    "    - Platform: which social media platform the user is associated with (ex: Instagram, Twitter, Facebook, etc.)  \n",
    "    - Daily_Usage_Time (minutes): time spent per day on the platform, measured in minutes  \n",
    "    - Posts_Per_Day / Likes_Received_Per_Day / Comments_Received_Per_Day / Messages_Sent_Per_Day: daily activity/engagement counts (all are “counts per day”)  \n",
    "    - Dominant_Emotion: the main emotion label for that user/day (ex: Happiness, Sadness, Anger, Anxiety, Boredom, Neutral)  \n",
    "\n",
    "  - Shortcomings / limitations:  \n",
    "    - Small dataset size (especially val/test). That limits how confident we can be about patterns/generalization.  \n",
    "    - Some community analyses report messy rows / parsing issues (ex: a “User_ID” that turns into text) and potential duplicates / inconsistencies in splits, so we should check types, bad rows, duplicates, and whether IDs overlap across files.  \n",
    "    - This is behavior data + a label, but we don’t have context like why the person felt that way, mental health history, or real clinical measures. So “emotion” here is just what the dataset defines, not a diagnosis.  \n",
    "\n",
    "- Dataset #4\n",
    "  - Dataset Name: **Social Media and Mental Health** (survey; `smmh.csv`)\n",
    "  - Link to the dataset (official Kaggle page): `https://www.kaggle.com/datasets/souvikahmed071/social-media-and-mental-health`\n",
    "  - Reproducible raw CSV mirror used in this repo (no Kaggle login required): `https://raw.githubusercontent.com/Daerkns/correlation-between-social-media-and-mental-health/main/smmh.csv`\n",
    "  - Number of observations: **481** survey responses (rows)\n",
    "  - Number of variables: **21** columns\n",
    "  - Description of the variables most relevant to this project:\n",
    "    - Demographics/controls: age, gender, relationship status, occupation status, affiliated organization type\n",
    "    - Social media usage: whether they use social media, which platforms (comma-separated list), and average time spent per day (categorical bins)\n",
    "    - Wellbeing / mental health proxies (mostly Likert 1–5): distractedness, worries, concentration difficulty, social comparison frequency + feelings about comparisons, validation seeking, feeling depressed/down, interest fluctuation, sleep issues\n",
    "  - Shortcomings / limitations:\n",
    "    - Cross-sectional and self-reported survey data (no causal conclusions; subject to recall/social desirability bias)\n",
    "    - Does not include direct “active interaction” counts (posting/commenting/DMs); we will treat it as a **supporting** dataset and use available proxies (time-spent, platforms, comparison/validation items)\n",
    "    - Potential sample bias (survey respondents are not representative of all adults)\n",
    "    - Small number of potentially inconsistent responses (e.g., `Do you use social media? = No` but other usage questions answered) that we will flag and handle explicitly in cleaning\n",
    "- Dataset #5\n",
    "  - Dataset Name: **Screen Time vs Mental Wellness Survey (2025)** (survey; `ScreenTime vs MentalWellness.csv`)\n",
    "  - Link to the dataset (official Kaggle page): `https://www.kaggle.com/datasets/adharshinikumar/screentime-vs-mentalwellness-survey-2025`\n",
    "  - Number of observations: **400**\n",
    "  - Number of variables: **15**\n",
    "  - Description of the variables most relevant to this project:\n",
    "    - Leisure Screen Time (Hours): Total time spent on social media, gaming, streaming. This serves as a proxy for passive digital exposure.\n",
    "    - Sleep Hours: Total sleep duration.\n",
    "    - Sleep Quality (1-5 scale): Self-reported sleep-related measure indicating rest quality.\n",
    "    - Stress Level (0-10 scale): Self-reported stress level.\n",
    "    - Mental Wellness Indicators: Composite or self-rated measure of overall mental wellbeing indicating mood, energy, focus.\n",
    "  - Descriptions of any shortcomings this dataset has with respect to the project:\n",
    "    - Not social media specific making it impossible to isolate the effects of social media alone\n",
    "    - Does not distinguish between passive consumption and active interaction.\n",
    "    - Most variables are self-reported, introducing potential reporting bias.\n",
    "    - Composite wellness indicator aggregates multiple dimensions, which may mask specific pathways between screen time and individual outcomes\n",
    "  \n",
    "We will not directly row-merge these datasets because they do not share a common person-level key (no shared `user_id`) and are collected from different samples/platform contexts.  Instead, we will combine them through a **harmonized analysis framework**:\n",
    "\n",
    "- Define comparable constructs across datasets: passive-use exposure, active-use behavior (when available), stress/happiness (or closest wellbeing proxies), and common controls (age, gender, work/lifestyle variables).\n",
    "- Run dataset-specific cleaning + regression/association analyses separately.\n",
    "- Standardize key predictors/outcomes (z-scores where needed) so effect directions/magnitudes are comparable.\n",
    "- Use Dataset #1 (`instagram_usage_lifestyle.csv`) as the main analysis, and use the other datasets (e.g., `smmh.csv`, mental-health balance/screen-time datasets) as robustness/supporting checks.\n",
    "- Synthesize findings by comparing whether associations are consistent in direction and practical size across datasets, while clearly noting differences in measurement and limitations.\n",
    "\n",
    "This approach lets us use multiple data sources without forcing invalid joins and keeps conclusions appropriately correlational.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# This cell downloads raw data into `data/00-raw/`.\n",
    "\n",
    "# If you're missing packages in your environment, uncomment this line\n",
    "# %pip install pandas numpy matplotlib seaborn\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Ensure expected data directories exist.\n",
    "os.makedirs('data/00-raw', exist_ok=True)\n",
    "os.makedirs('data/01-interim', exist_ok=True)\n",
    "os.makedirs('data/02-processed', exist_ok=True)\n",
    "\n",
    "# Dataset #2\n",
    "dataset_2_URL = 'https://raw.githubusercontent.com/NeenosY/Group148_WI26/refs/heads/master/data/00-raw/Mental_Health_and_Social_Media_Balance_Dataset.csv'\n",
    "dataset_2_LOCAL = 'data/00-raw/Mental_Health_and_Social_Media_Balance_Dataset.csv'\n",
    "\n",
    "# Dataset #3 (Social Media Usage and Emotional Well-Being)\n",
    "EMIR_DIR = 'data/00-raw/emirhanai'\n",
    "EMIR_FILES = ['train.csv', 'val.csv', 'test.csv']\n",
    "\n",
    "# Dataset #4 (Social Media and Mental Health)\n",
    "SMMH_URL = 'https://raw.githubusercontent.com/Daerkns/correlation-between-social-media-and-mental-health/main/smmh.csv'\n",
    "SMMH_LOCAL = 'data/00-raw/smmh.csv'\n",
    "\n",
    "def download_if_missing(url: str, local_path: str) -> None:\n",
    "    if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "        print(f\"Already exists: {local_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Downloading to: {local_path}\")\n",
    "    urllib.request.urlretrieve(url, local_path)\n",
    "    print(f\"Downloaded: {local_path} ({os.path.getsize(local_path)} bytes)\")\n",
    "\n",
    "download_if_missing(dataset_2_URL, dataset_2_LOCAL)\n",
    "download_if_missing(SMMH_URL, SMMH_LOCAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1: Instagram User Activity and Wellbeing (Kaggle)\n",
    "\n",
    "#### Overview\n",
    "This dataset (`instagram_usage_lifestyle.csv`) contains user-level Instagram activity, wellbeing outcomes, and demographic/lifestyle controls, with one row per user. For this checkpoint, we treat it as cross-sectional data. In our current run, the raw dataset contains **1,547,896 rows** and **58 columns**; after applying the age 18+ restriction, the analysis table contains **1,401,638 rows** and **14 selected columns**.\n",
    "\n",
    "#### Important Metrics in the Dataset\n",
    "- **Passive-use predictor:** `time_on_feed_per_day` (minutes/day)  \n",
    "  - Higher values indicate more passive feed consumption.\n",
    "- **Active-use predictor:** `posts_created_per_week` (posts/week)  \n",
    "  - Higher values indicate more active participation through posting.\n",
    "- **Primary wellbeing outcomes:**  \n",
    "  - `perceived_stress_score` (stress level scale in the dataset)  \n",
    "  - `self_reported_happiness` (happiness level scale in the dataset)\n",
    "- **Control variables used in this checkpoint:**  \n",
    "  - `age`, `gender`, `country`, `urban_rural`, `income_level`, `employment_status`, `education_level`, `exercise_hours_per_week`, `sleep_hours_per_night`, `weekly_work_hours`\n",
    "\n",
    "These metrics are directly tied to our research question about how passive versus active social media behavior is associated with stress and happiness among adults.\n",
    "\n",
    "#### Data Wrangling and Cleaning Decisions\n",
    "- Load raw data from `data/00-raw/instagram_usage_lifestyle.csv`\n",
    "- Check size, duplicates, missingness, and data types\n",
    "- Map core variables for age, passive-use, active-use, stress, and happiness\n",
    "- Restrict to **adults (18+)**\n",
    "- Keep selected predictors, outcomes, and controls for analysis\n",
    "- Flag outliers using an **IQR-based rule** for transparency\n",
    "- Save outputs to:\n",
    "  - `data/01-interim/social_media_user_activity_interim.csv`\n",
    "  - `data/02-processed/social_media_user_activity_cleaned.csv`\n",
    "\n",
    "For selected analysis variables, missingness is effectively zero in this run, so no imputation was needed.\n",
    "\n",
    "#### Potential Concerns and Biases\n",
    "- **Cross-sectional observational structure:** We cannot make causal claims; results are associational only.\n",
    "- **Measurement/unit mismatch:** Passive-use is minutes/day while active-use is posts/week; direct effect-size comparison requires care (and potential standardization in later modeling).\n",
    "- **Potential external validity concern:** Near-zero missingness across many fields suggests the dataset may be synthetic or heavily processed, which could limit real-world generalizability.\n",
    "- **Residual confounding:** Even with controls, unmeasured factors may still influence estimated associations.\n",
    "- **Operationalization limitation:** Current passive/active definitions use one variable each; later analysis may use composite indicators (likes/comments/DMs/time components) for a fuller behavioral representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset #1 wrangling (Social Media User Activity Dataset)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "RAW_DIR = Path(\"data/00-raw\")\n",
    "INTERIM_DIR = Path(\"data/01-interim\")\n",
    "PROCESSED_DIR = Path(\"data/02-processed\")\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "csv_path = RAW_DIR / \"instagram_usage_lifestyle.csv\"\n",
    "if not csv_path.exists():\n",
    "    all_names = [p.name for p in sorted(RAW_DIR.glob(\"*.csv\"))]\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected file '{csv_path.name}' not found in data/00-raw/. \"\n",
    "        f\"Current CSV files: {all_names}\"\n",
    "    )\n",
    "\n",
    "df_raw = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Using file: {csv_path.name}\")\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "print(\"\\nColumns:\")\n",
    "for c in df_raw.columns:\n",
    "    print(\"-\", c)\n",
    "\n",
    "display(df_raw.head())\n",
    "\n",
    "# ---------- Data quality checks ----------\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"\\nRows, columns:\", df.shape)\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "missing = (\n",
    "    df.isna()\n",
    "    .sum()\n",
    "    .to_frame(\"missing_count\")\n",
    "    .assign(missing_pct=lambda x: (x[\"missing_count\"] / len(df) * 100).round(2))\n",
    "    .sort_values(\"missing_count\", ascending=False)\n",
    ")\n",
    "print(\"\\nTop missingness columns:\")\n",
    "display(missing.head(25))\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "display(df.dtypes.to_frame(\"dtype\"))\n",
    "\n",
    "def suggest_columns(columns, keywords, regex=False):\n",
    "    out = []\n",
    "    for c in columns:\n",
    "        cl = str(c).lower()\n",
    "        if regex:\n",
    "            if any(re.search(k, cl) for k in keywords):\n",
    "                out.append(c)\n",
    "        else:\n",
    "            if any(k in cl for k in keywords):\n",
    "                out.append(c)\n",
    "    return out\n",
    "\n",
    "candidate_map = {\n",
    "    \"age\": suggest_columns(df.columns, [r\"(^|[_\\s\\-])age([_\\s\\-]|$)\"], regex=True),\n",
    "    \"passive_use\": suggest_columns(df.columns, [\"passive\", \"scroll\", \"browse\", \"view\", \"watch\", \"consume\", \"time\", \"minutes\"]),\n",
    "    \"active_use\": suggest_columns(df.columns, [\"active\", \"post\", \"comment\", \"like\", \"message\", \"dm\", \"interact\"]),\n",
    "    \"stress\": suggest_columns(df.columns, [\"stress\", \"anxiety\", \"anx\"]),\n",
    "    \"happiness\": suggest_columns(df.columns, [\"happiness\", \"happy\", \"wellbeing\", \"well-being\", \"mood\"]),\n",
    "}\n",
    "\n",
    "print(\"\\nCandidate columns by concept:\")\n",
    "for k, v in candidate_map.items():\n",
    "    print(f\"\\n{k}:\")\n",
    "    if v:\n",
    "        for name in v:\n",
    "            print(\" -\", name)\n",
    "    else:\n",
    "        print(\" - (no obvious match found)\")\n",
    "\n",
    "# ---------- Cleaning config ----------\n",
    "col_map = {\n",
    "    \"age\": \"age\",\n",
    "    \"passive_use\": \"time_on_feed_per_day\",\n",
    "    \"active_use\": \"posts_created_per_week\",\n",
    "    \"stress\": \"perceived_stress_score\",\n",
    "    \"happiness\": \"self_reported_happiness\",\n",
    "}\n",
    "\n",
    "control_cols = [\n",
    "    \"gender\",\n",
    "    \"country\",\n",
    "    \"urban_rural\",\n",
    "    \"income_level\",\n",
    "    \"employment_status\",\n",
    "    \"education_level\",\n",
    "    \"exercise_hours_per_week\",\n",
    "    \"sleep_hours_per_night\",\n",
    "    \"weekly_work_hours\",\n",
    "]\n",
    "\n",
    "\n",
    "def to_snake(s):\n",
    "    s = str(s).strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "\n",
    "df_clean = df.copy()\n",
    "df_clean = df_clean.rename(columns={c: to_snake(c) for c in df_clean.columns})\n",
    "\n",
    "mapped = {k: (to_snake(v) if v is not None else None) for k, v in col_map.items()}\n",
    "control_cols_snake = [to_snake(c) for c in control_cols]\n",
    "\n",
    "selected_cols = [v for v in mapped.values() if v is not None] + control_cols_snake\n",
    "selected_cols = [c for c in selected_cols if c in df_clean.columns]\n",
    "\n",
    "if selected_cols:\n",
    "    df_clean = df_clean[selected_cols].copy()\n",
    "else:\n",
    "    print(\"\\nNo col_map/control_cols selected yet. Keeping all columns for now.\")\n",
    "\n",
    "for key in [\"age\", \"passive_use\", \"active_use\", \"stress\", \"happiness\"]:\n",
    "    col = mapped.get(key)\n",
    "    if col is not None and col in df_clean.columns:\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
    "\n",
    "if mapped[\"age\"] is not None and mapped[\"age\"] in df_clean.columns:\n",
    "    before = len(df_clean)\n",
    "    df_clean = df_clean[df_clean[mapped[\"age\"]] >= 18]\n",
    "    print(f\"Age filter (18+): {before} -> {len(df_clean)} rows\")\n",
    "else:\n",
    "    print(\"Age column not mapped; 18+ filter skipped.\")\n",
    "\n",
    "before_dup = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(f\"Drop duplicates: {before_dup} -> {len(df_clean)} rows\")\n",
    "\n",
    "required_cols = [\n",
    "    mapped[k]\n",
    "    for k in [\"passive_use\", \"active_use\", \"stress\", \"happiness\"]\n",
    "    if mapped[k] is not None and mapped[k] in df_clean.columns\n",
    "]\n",
    "if required_cols:\n",
    "    before_req = len(df_clean)\n",
    "    df_clean = df_clean.dropna(subset=required_cols)\n",
    "    print(f\"Drop NA in required vars: {before_req} -> {len(df_clean)} rows\")\n",
    "else:\n",
    "    print(\"Required vars not fully mapped yet; NA filtering skipped.\")\n",
    "\n",
    "numeric_cols = df_clean.select_dtypes(include=[np.number]).columns.tolist()\n",
    "outlier_counts = {}\n",
    "for c in numeric_cols:\n",
    "    s = df_clean[c].dropna()\n",
    "    if len(s) < 5:\n",
    "        outlier_counts[c] = 0\n",
    "        continue\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    if iqr == 0:\n",
    "        outlier_counts[c] = 0\n",
    "        continue\n",
    "    lo, hi = q1 - 1.5 * iqr, q3 + 1.5 * iqr\n",
    "    outlier_counts[c] = int(((df_clean[c] < lo) | (df_clean[c] > hi)).sum())\n",
    "\n",
    "outlier_report = pd.Series(outlier_counts, name=\"outlier_count\").sort_values(ascending=False).to_frame()\n",
    "print(\"\\nOutlier counts (IQR):\")\n",
    "display(outlier_report.head(20))\n",
    "\n",
    "interim_path = INTERIM_DIR / \"social_media_user_activity_interim.csv\"\n",
    "processed_path = PROCESSED_DIR / \"social_media_user_activity_cleaned.csv\"\n",
    "\n",
    "df_clean.to_csv(interim_path, index=False)\n",
    "df_clean.to_csv(processed_path, index=False)\n",
    "\n",
    "print(\"\\nFinal cleaned shape:\", df_clean.shape)\n",
    "print(\"Saved interim:\", interim_path)\n",
    "print(\"Saved processed:\", processed_path)\n",
    "display(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2: Mental Health and Social Media Balance Dataset\n",
    "\n",
    "The Mental Health and Social Media Balance Dataset comes from self reported surveys where people shared info about how much time they spend on social media and how they’re doing mentally. It includes stuff like average daily hours on apps, self rated stress levels, the quality of their sleep, a happiness score, and some basic demographics like age and gender too. The whole point of the dataset is to look at whether there’s any connection between heavy social media use and things like stress, sleep problems, or just feeling less happy overall. An important thing to not is that everything was collected at basically the same moment in time. So we can spot patterns and associations (like “people who report 4+ hours of scrolling tend to also report higher stress”), but we can’t say for sure that one thing is causing the other. This dataset will mainly be used to enforce our other datasets as this one can only be used to showcase consumption of social medias effect on wellbeing as a whole (not passive consumption versus active interaction). It lacks the data of whether or not the reported person is active or not on the platforms they spent time on.\n",
    "\n",
    "### Important metrics in the dataset:\n",
    "- Daily Screen Time (Hours)\n",
    "- Sleep Quality (1-10)\n",
    "  - 1 Being the worst sleep (No reported 1's)\n",
    "  - 10 Being the best sleep\n",
    "- Stress Level (1-10)\n",
    "  - 1 Being no stress (No reported 1's)\n",
    "  - 10 Being the highest level of stress\n",
    "- Happiness Index (1-10)\n",
    "  - 1 Being the least happy (No reports lower than 4)\n",
    "  - 10 Being the most happy\n",
    "These are the metrics that are directly tied to our research question on the effect of social media use (Screen Time (Hours)) on an adults mental wellbeing. Again, although this does not directly answer our question of the effects of the different kinds of social media use (passive consumption versus active interaction), it contains critical data to conclude whether or not social media even has an effect on an Adults mental wellbeing in the first place.\n",
    "\n",
    "### Potential concerns and biases:\n",
    "- Age (16-49) // Potential bias\n",
    "  - There are users under the age of 18 who reported to the dataset. These must be cleaned out to fit our research questions demographics (18+).\n",
    "  - There is a large range of ages (18-49 after cleaning), in which age biases might need to be taken into account. Things such, \"as are older people more happy in general?\", \"Do younger people use social media more often than older people?\", etc.\n",
    "- Gender (Male, Female, Other) // Potential bias\n",
    "  - Similarly to the differences in age, there might be biases of happiness, stress, screen time, and sleep quality when it comes to differences in gender (much higher or lower overalls despite screen time). These need to be taken into account and checked before coming to a conclusion with the compiled data.\n",
    "- Exercise Frequency (0-7 days a week) // Potential bias\n",
    "  - Need to check the overall comparison of whether higher or lower excerise frequency directly relate to happiness or stress levels to conclude whether it may or may not be a bias.\n",
    "- Self Report bias/concern // Potential bias and/or concern\n",
    "  - Since the data was mostly, if not all, self reported, there may be some innaccuracy in the data. This can come in the form of underreporting social media use or overinflating happiness/stress levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_2 = pd.read_csv(\"data/00-raw/Mental_Health_and_Social_Media_Balance_Dataset.csv\")\n",
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data already looks relatively clean and all column values have relevancy towards our research topic.\n",
    "\n",
    "We must first check whether there are any missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_2.isnull().any())\n",
    "print(\"Number of missing values: \" + str(dataset_2.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values that need to be dealt with.\n",
    "\n",
    "We are only interested in the responses of those 18 and older so we must filter out the extra responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_2[dataset_2['Age'] >= 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now check impossible values (ones that exceed the 1-10 limits or 7 day week limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All max and min values are valid in their respective ranges.\n",
    "\n",
    "Finally, lets clean up the column names and values to be more visually appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnNames = ['ID', 'Age', 'Gender', 'Screen Time', 'Sleep Quality', 'Stress Level', 'Days Without Social Media', 'Exercise Frequency', 'Platform', 'Happiness Level']\n",
    "dataset_2.columns = columnNames\n",
    "columnValues = ['Sleep Quality', 'Stress Level', 'Days Without Social Media', 'Exercise Frequency', 'Happiness Level']\n",
    "dataset_2 = dataset_2.drop(columns=['ID'])\n",
    "dataset_2[columnValues] = dataset_2[columnValues].astype(int)\n",
    "dataset_2 = dataset_2.reset_index(drop=True)\n",
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many responses are left after cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2.to_csv(\"data/02-processed/Mental_Health_and_Social_Media_Balance_Dataset_processed.csv\", index=False)\n",
    "dataset_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #3: Social Media Usage and Emotional Well-Being (emirhanai)\n",
    "\n",
    "- **Dataset Name:** Social Media Usage and Emotional Well-Being\n",
    "- **Link to dataset:** https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being\n",
    "- **Raw files used:** `train.csv`, `val.csv`, `test.csv` (stored in `data/00-raw/emirhanai/`)\n",
    "- **Number of observations:** printed in the code cells below (train/val/test and combined)\n",
    "- **Number of variables:** printed in the code cells below\n",
    "\n",
    "**What this dataset contains:**\n",
    "Each row represents a single user record with:\n",
    "- Demographics (e.g., Age in years, Gender)\n",
    "- Social media context (e.g., Platform)\n",
    "- Usage/activity metrics (e.g., daily usage time in minutes, posts/likes/comments/messages per day)\n",
    "- A label representing emotional state (e.g., Dominant_Emotion)\n",
    "\n",
    "**Variables most relevant to our project:**\n",
    "- Daily usage time (minutes) and daily activity counts (posts/likes/comments/messages)\n",
    "- Platform + demographics (Age, Gender) for context/controls\n",
    "- Emotion label (Dominant_Emotion) as the outcome\n",
    "\n",
    "**Shortcomings / concerns:**\n",
    "- Observational data: we can talk about associations, not causation.\n",
    "- Emotion label is not a clinical diagnosis.\n",
    "- CSV may contain messy rows (we handle this during loading and cleaning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "raw_dir = Path(\"data/00-raw/emirhanai\")\n",
    "interim_dir = Path(\"data/01-interim\")\n",
    "processed_dir = Path(\"data/02-processed\")\n",
    "\n",
    "interim_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_path = raw_dir / \"train.csv\"\n",
    "val_path   = raw_dir / \"val.csv\"\n",
    "test_path  = raw_dir / \"test.csv\"\n",
    "\n",
    "train_path, val_path, test_path\n",
    "\n",
    "def safe_read_csv(path):\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "\n",
    "train = safe_read_csv(train_path)\n",
    "val   = safe_read_csv(val_path)\n",
    "test  = safe_read_csv(test_path)\n",
    "\n",
    "print(\"train:\", train.shape)\n",
    "print(\"val:  \", val.shape)\n",
    "print(\"test: \", test.shape)\n",
    "\n",
    "\n",
    "df = pd.concat([train, val, test], ignore_index=True)\n",
    "print(\"combined shape:\", df.shape)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:** Imported the libraries we need and define the file paths for Dataset #3 (train/val/test). Also make sure the interim and processed folders exist so we can save cleaned data later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data:** Read `train.csv`, `val.csv`, and `test.csv` from `data/00-raw/emirhanai/`. A few lines are malformed so to have the notebook run top-to-bottom without crashing we used a diff CSV loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine splits:** Concatenate train/val/test into one dataframe for cleaning and exploratory checks. This does not change the data values; it just makes it easier to analyze everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make columns easier to work with (Tidy)\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.replace(\" \", \"_\")\n",
    "      .str.replace(\"(\", \"\", regex=False)\n",
    "      .str.replace(\")\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tidy check:** Confirm the dataset is already tidy (each row is one observation and each column is one variable). Also standardize column names to make them easier to reference in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Age to numeric (bad strings become NaN)\n",
    "if \"Age\" in df.columns:\n",
    "    df[\"Age\"] = pd.to_numeric(df[\"Age\"], errors=\"coerce\")\n",
    "\n",
    "# Same idea for usage + counts if they exist\n",
    "num_cols = [\n",
    "    \"Daily_Usage_Time_minutes\",\n",
    "    \"Posts_Per_Day\",\n",
    "    \"Likes_Received_Per_Day\",\n",
    "    \"Comments_Received_Per_Day\",\n",
    "    \"Messages_Sent_Per_Day\"\n",
    "]\n",
    "\n",
    "for c in num_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data types:** Convert columns like Age and activity metrics to numeric types. Any non-numeric values become missing (`NaN`), which we handle later during cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rows (observations):\", df.shape[0])\n",
    "print(\"Columns (variables):\", df.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset size:** Report the number of observations (rows) and variables (columns) so we can document dataset size for the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Data\n",
    "missing_count = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False).round(2)\n",
    "\n",
    "missing_table = pd.DataFrame({\n",
    "    \"missing_count\": missing_count,\n",
    "    \"missing_pct\": missing_pct\n",
    "})\n",
    "\n",
    "display(missing_table[missing_table[\"missing_count\"] > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data:** Calculate how much data is missing in each column and check where missingness happens. We also do a simple check to see if missing values are more common in some groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flag_suspicious\"] = False\n",
    "\n",
    "# Age suspicious\n",
    "if \"Age\" in df.columns:\n",
    "    df.loc[(df[\"Age\"] < 10) | (df[\"Age\"] > 100), \"flag_suspicious\"] = True\n",
    "\n",
    "# Daily usage suspicious (minutes in a day is 0–1440)\n",
    "if \"Daily_Usage_Time_minutes\" in df.columns:\n",
    "    df.loc[(df[\"Daily_Usage_Time_minutes\"] < 0) | (df[\"Daily_Usage_Time_minutes\"] > 1440), \"flag_suspicious\"] = True\n",
    "\n",
    "# Negative counts suspicious\n",
    "count_cols = [\"Posts_Per_Day\",\"Likes_Received_Per_Day\",\"Comments_Received_Per_Day\",\"Messages_Sent_Per_Day\"]\n",
    "for c in count_cols:\n",
    "    if c in df.columns:\n",
    "        df.loc[df[c] < 0, \"flag_suspicious\"] = True\n",
    "\n",
    "print(\"Suspicious rows:\", int(df[\"flag_suspicious\"].sum()))\n",
    "display(df[df[\"flag_suspicious\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers & suspicious values:** Flag entries that are outside realistic ranges. We flag first so we can inspect before deciding to remove anything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save interim version (after dtype fixes + suspicious flag)\n",
    "df.to_csv(interim_dir / \"emirhanai_interim.csv\", index=False)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1) duplicates\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates()\n",
    "print(\"Dropped duplicates:\", before - len(df_clean))\n",
    "\n",
    "# 2) suspicious\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean[df_clean[\"flag_suspicious\"] == False].copy()\n",
    "print(\"Dropped suspicious:\", before - len(df_clean))\n",
    "\n",
    "# 3) missingness handling (drop rows missing key fields)\n",
    "key_cols = [\"Age\", \"Gender\", \"Platform\", \"Daily_Usage_Time_minutes\", \"Dominant_Emotion\"]\n",
    "key_cols = [c for c in key_cols if c in df_clean.columns]\n",
    "\n",
    "before = len(df_clean)\n",
    "df_clean = df_clean.dropna(subset=key_cols)\n",
    "print(\"Dropped missing key fields:\", before - len(df_clean))\n",
    "\n",
    "# Save processed\n",
    "df_clean.to_csv(processed_dir / \"emirhanai_processed.csv\", index=False)\n",
    "print(\"Final cleaned shape:\", df_clean.shape)\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning & saving:** Remove duplicates and clearly suspicious rows, then handle missing values in key columns. Save an interim dataset (`data/01-interim/`) and the final cleaned dataset (`data/02-processed/`) for later analysis/modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Histogram (daily minutes)\n",
    "if \"Daily_Usage_Time_minutes\" in df_clean.columns:\n",
    "    plt.figure()\n",
    "    df_clean[\"Daily_Usage_Time_minutes\"].hist(bins=20)\n",
    "    plt.xlabel(\"Daily Usage Time (minutes)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# Bar chart (emotion)\n",
    "if \"Dominant_Emotion\" in df_clean.columns:\n",
    "    plt.figure()\n",
    "    df_clean[\"Dominant_Emotion\"].value_counts().plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Dominant Emotion\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary + visuals (optional):** Showed basic summary statistics and simple plots to better understand distributions (like daily usage time) and class balance (dominant emotion). This helps verify the dataset looks reasonable after cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #4: Social Media and Mental Health (`smmh.csv`)\n",
    "\n",
    "**Official dataset page (citation):** `https://www.kaggle.com/datasets/souvikahmed071/social-media-and-mental-health`\n",
    "\n",
    "**How we download it reproducibly for this repo:** Kaggle downloads require login/terms acceptance, so for reproducibility we download the same `smmh.csv` from a public raw mirror into `data/00-raw/` using the setup cell above.\n",
    "\n",
    "Each row is one survey response (timestamped). Columns include demographics, social media usage (platforms + time-spent category), and several mental-health / wellbeing proxy items (mostly Likert 1–5).\n",
    "\n",
    "In the wrangling below we:\n",
    "- Rename verbose survey-question column names to short `snake_case` names\n",
    "- Parse timestamps and coerce numeric Likert items\n",
    "- Standardize key categorical values (e.g., gender labels)\n",
    "- Engineer a numeric **hours/day** proxy from the time-spent categories\n",
    "- Expand the comma-separated platforms field into a small set of indicator columns\n",
    "- Check missingness, outliers, and a small set of internal inconsistencies\n",
    "- Save a processed dataset to `data/02-processed/smmh_processed.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "raw_path = 'data/00-raw/smmh.csv'\n",
    "\n",
    "# Load raw data (downloaded in the setup cell)\n",
    "df_raw = pd.read_csv(raw_path, skipinitialspace=True)\n",
    "df_raw.columns = [c.strip() for c in df_raw.columns]\n",
    "\n",
    "rename_map = {\n",
    "    'Timestamp': 'timestamp',\n",
    "    '1. What is your age?': 'age',\n",
    "    '2. Gender': 'gender',\n",
    "    '3. Relationship Status': 'relationship_status',\n",
    "    '4. Occupation Status': 'occupation_status',\n",
    "    '5. What type of organizations are you affiliated with?': 'organization_affiliation',\n",
    "    '6. Do you use social media?': 'uses_social_media_answer',\n",
    "    '7. What social media platforms do you commonly use?': 'platforms',\n",
    "    '8. What is the average time you spend on social media every day?': 'avg_daily_time',\n",
    "    '9. How often do you find yourself using Social media without a specific purpose?': 'sm_no_purpose_freq',\n",
    "    '10. How often do you get distracted by Social media when you are busy doing something?': 'sm_distracted_freq',\n",
    "    \"11. Do you feel restless if you haven't used Social media in a while?\": 'sm_restless_freq',\n",
    "    '12. On a scale of 1 to 5, how easily distracted are you?': 'easily_distracted',\n",
    "    '13. On a scale of 1 to 5, how much are you bothered by worries?': 'bothered_by_worries',\n",
    "    '14. Do you find it difficult to concentrate on things?': 'difficulty_concentrating',\n",
    "    '15. On a scale of 1-5, how often do you compare yourself to other successful people through the use of social media?': 'compare_to_successful_freq',\n",
    "    '16. Following the previous question, how do you feel about these comparisons, generally speaking?': 'feel_about_comparisons',\n",
    "    '17. How often do you look to seek validation from features of social media?': 'seek_validation_freq',\n",
    "    '18. How often do you feel depressed or down?': 'depressed_or_down_freq',\n",
    "    '19. On a scale of 1 to 5, how frequently does your interest in daily activities fluctuate?': 'interest_fluctuation',\n",
    "    '20. On a scale of 1 to 5, how often do you face issues regarding sleep?': 'sleep_issues',\n",
    "}\n",
    "\n",
    "missing_cols = sorted(set(rename_map) - set(df_raw.columns))\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Unexpected raw columns (missing expected): {missing_cols}\")\n",
    "\n",
    "# Rename columns\n",
    "df = df_raw.rename(columns=rename_map).copy()\n",
    "\n",
    "# Parse timestamp + age\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "\n",
    "# Standardize string columns\n",
    "string_cols = [\n",
    "    'gender',\n",
    "    'relationship_status',\n",
    "    'occupation_status',\n",
    "    'organization_affiliation',\n",
    "    'uses_social_media_answer',\n",
    "    'platforms',\n",
    "    'avg_daily_time',\n",
    "    'feel_about_comparisons',\n",
    "]\n",
    "for c in string_cols:\n",
    "    df[c] = df[c].astype('string').str.strip()\n",
    "\n",
    "# Normalize gender labels (keep it simple + transparent)\n",
    "def _normalize_gender(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip()\n",
    "    s_low = s.lower()\n",
    "\n",
    "    if s_low in {'nb', 'nonbinary', 'non-binary'}:\n",
    "        return 'Non-binary'\n",
    "    if s_low in {'unsure'}:\n",
    "        return 'Unsure'\n",
    "    if s_low in {'trans'}:\n",
    "        return 'Trans'\n",
    "\n",
    "    # Common values like 'Male'/'Female' stay as-is (titlecased)\n",
    "    return s.title()\n",
    "\n",
    "df['gender'] = df['gender'].map(_normalize_gender)\n",
    "\n",
    "# Coerce Likert-style items to numeric\n",
    "likert_cols = [\n",
    "    'sm_no_purpose_freq',\n",
    "    'sm_distracted_freq',\n",
    "    'sm_restless_freq',\n",
    "    'easily_distracted',\n",
    "    'bothered_by_worries',\n",
    "    'difficulty_concentrating',\n",
    "    'compare_to_successful_freq',\n",
    "    'seek_validation_freq',\n",
    "    'depressed_or_down_freq',\n",
    "    'interest_fluctuation',\n",
    "    'sleep_issues',\n",
    "]\n",
    "for c in likert_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').astype('Int64')\n",
    "\n",
    "print('Raw shape:', df_raw.shape)\n",
    "print('Renamed/typed shape:', df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature engineering: platforms + time spent ---\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Convert Yes/No to a boolean indicator (keep original + a cleaned version)\n",
    "df['uses_social_media_original'] = (\n",
    "    df['uses_social_media_answer']\n",
    "      .str.lower()\n",
    "      .map({'yes': True, 'no': False})\n",
    "      .astype('boolean')\n",
    ")\n",
    "\n",
    "common_platforms = [\n",
    "    'Facebook', 'Instagram', 'Twitter', 'YouTube',\n",
    "    'TikTok', 'Snapchat', 'Discord', 'Reddit', 'Pinterest'\n",
    "]\n",
    "_common_set = set(common_platforms)\n",
    "\n",
    "def _normalize_platform(p: str) -> str:\n",
    "    p = p.strip()\n",
    "    p_low = p.lower()\n",
    "\n",
    "    mapping = {\n",
    "        'youtube': 'YouTube',\n",
    "        'tik tok': 'TikTok',\n",
    "        'tiktok': 'TikTok',\n",
    "        'fb': 'Facebook',\n",
    "        'x': 'Twitter',\n",
    "    }\n",
    "    if p_low in mapping:\n",
    "        return mapping[p_low]\n",
    "\n",
    "    # Keep capitalization consistent for common platforms\n",
    "    for canon in common_platforms:\n",
    "        if p_low == canon.lower():\n",
    "            return canon\n",
    "\n",
    "    return p.title()\n",
    "\n",
    "def _parse_platforms(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    items = [i.strip() for i in str(x).split(',') if i.strip()]\n",
    "    norm = [_normalize_platform(i) for i in items]\n",
    "\n",
    "    # De-duplicate while preserving order\n",
    "    out = []\n",
    "    seen = set()\n",
    "    for p in norm:\n",
    "        if p not in seen:\n",
    "            out.append(p)\n",
    "            seen.add(p)\n",
    "    return out\n",
    "\n",
    "platform_list = df['platforms'].map(_parse_platforms)\n",
    "df['platform_count'] = platform_list.map(len)\n",
    "df['platforms_clean'] = platform_list.map(lambda lst: ', '.join(lst) if lst else pd.NA).astype('string')\n",
    "\n",
    "for p in common_platforms:\n",
    "    col = f\"uses_{p.lower()}\".replace(' ', '_')\n",
    "    df[col] = platform_list.map(lambda lst, p=p: p in lst).astype('boolean')\n",
    "\n",
    "df['uses_other_platform'] = platform_list.map(lambda lst: any(p not in _common_set for p in lst)).astype('boolean')\n",
    "\n",
    "# Map time-spent bins to an approximate numeric hours/day proxy.\n",
    "# Midpoints are used for closed intervals; \"More than 5 hours\" is set to 5.5 as a conservative constant.\n",
    "time_to_hours = {\n",
    "    'Less than an Hour': 0.5,\n",
    "    'Between 1 and 2 hours': 1.5,\n",
    "    'Between 2 and 3 hours': 2.5,\n",
    "    'Between 3 and 4 hours': 3.5,\n",
    "    'Between 4 and 5 hours': 4.5,\n",
    "    'More than 5 hours': 5.5,\n",
    "}\n",
    "df['avg_daily_hours'] = df['avg_daily_time'].map(time_to_hours).astype('Float64')\n",
    "\n",
    "# --- Data quality checks: missingness, outliers, inconsistencies ---\n",
    "\n",
    "print('\\nAge range (min/max):', df['age'].min(), df['age'].max())\n",
    "print('Age quantiles:')\n",
    "print(df['age'].quantile([0, 0.01, 0.25, 0.5, 0.75, 0.99, 1]).to_string())\n",
    "\n",
    "# Flag ages that are suspicious for an \"adults 18+\" research question\n",
    "suspicious_age_mask = (df['age'] < 18) | (df['age'] > 100)\n",
    "print('\\nSuspicious ages (<18 or >100):', int(suspicious_age_mask.sum()))\n",
    "if suspicious_age_mask.any():\n",
    "    display(df.loc[suspicious_age_mask, ['timestamp', 'age', 'gender']].head(10))\n",
    "\n",
    "# Missingness summary\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().mean() * 100).round(2)\n",
    "missing_table = pd.DataFrame({'missing_count': missing, 'missing_pct': missing_pct}).query('missing_count > 0')\n",
    "print('\\nMissingness (only columns with missing values):')\n",
    "display(missing_table)\n",
    "\n",
    "# Inconsistency: answered \"No\" to using social media but still provided platforms or time spent\n",
    "inferred_use = (df['platform_count'] > 0) | df['avg_daily_hours'].notna()\n",
    "inconsistent = (df['uses_social_media_original'] == False) & inferred_use\n",
    "print('\\nInconsistent rows (uses_social_media_original == False but usage fields present):', int(inconsistent.sum()))\n",
    "if inconsistent.any():\n",
    "    display(df.loc[inconsistent, ['uses_social_media_answer', 'platforms', 'avg_daily_time', 'platform_count']].head(10))\n",
    "\n",
    "# Cleaning rule: keep the original answer, but also create a \"clean\" usage boolean that\n",
    "# treats any reported usage fields as evidence of actual use.\n",
    "df['uses_social_media'] = (\n",
    "    df['uses_social_media_original']\n",
    "      .fillna(False)\n",
    "      .astype('boolean')\n",
    "    | inferred_use.astype('boolean')\n",
    ")\n",
    "\n",
    "# Check Likert ranges\n",
    "likert_minmax = df[likert_cols].agg(['min', 'max']).T\n",
    "out_of_range = (df[likert_cols] < 1) | (df[likert_cols] > 5)\n",
    "print('\\nLikert min/max (should be within 1–5):')\n",
    "display(likert_minmax)\n",
    "print('Out-of-range Likert entries (count):', int(out_of_range.sum().sum()))\n",
    "\n",
    "# --- Save processed dataset ---\n",
    "\n",
    "processed_cols = [\n",
    "    'timestamp', 'age', 'gender', 'relationship_status', 'occupation_status', 'organization_affiliation',\n",
    "    'uses_social_media_original', 'uses_social_media',\n",
    "    'avg_daily_time', 'avg_daily_hours',\n",
    "    'platforms_clean', 'platform_count',\n",
    "] + [\n",
    "    f\"uses_{p.lower()}\".replace(' ', '_') for p in common_platforms\n",
    "] + [\n",
    "    'uses_other_platform',\n",
    "    'sm_no_purpose_freq', 'sm_distracted_freq', 'sm_restless_freq',\n",
    "    'easily_distracted', 'bothered_by_worries', 'difficulty_concentrating',\n",
    "    'compare_to_successful_freq', 'feel_about_comparisons', 'seek_validation_freq',\n",
    "    'depressed_or_down_freq', 'interest_fluctuation', 'sleep_issues'\n",
    "]\n",
    "\n",
    "processed_path = 'data/02-processed/smmh_processed.csv'\n",
    "df_processed = df[processed_cols].copy()\n",
    "df_processed.to_csv(processed_path, index=False)\n",
    "\n",
    "print(f\"\\nSaved processed dataset to: {processed_path}\")\n",
    "print('Processed shape:', df_processed.shape)\n",
    "df_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Minimal EDA (sanity-check visuals) ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Distribution of time spent (numeric proxy)\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.histplot(df_processed['avg_daily_hours'].dropna().astype(float), bins=12)\n",
    "plt.title('Approx. Daily Social Media Use (hours/day)')\n",
    "plt.xlabel('avg_daily_hours')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gender distribution\n",
    "plt.figure(figsize=(7, 4))\n",
    "order = df_processed['gender'].value_counts(dropna=False).index\n",
    "sns.countplot(data=df_processed, y='gender', order=order)\n",
    "plt.title('Gender distribution')\n",
    "plt.xlabel('count')\n",
    "plt.ylabel('gender')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relationship between time spent and sleep issues (Likert 1–5)\n",
    "eda_tmp = df_processed.dropna(subset=['avg_daily_hours', 'sleep_issues']).copy()\n",
    "eda_tmp['avg_daily_hours'] = eda_tmp['avg_daily_hours'].astype(float)\n",
    "eda_tmp['sleep_issues'] = pd.to_numeric(eda_tmp['sleep_issues'], errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.regplot(\n",
    "    data=eda_tmp,\n",
    "    x='avg_daily_hours',\n",
    "    y='sleep_issues',\n",
    "    x_jitter=0.05,\n",
    "    y_jitter=0.05,\n",
    "    scatter_kws={'alpha': 0.25, 's': 18},\n",
    "    line_kws={'color': 'black'}\n",
    ")\n",
    "plt.title('Time on Social Media vs Sleep Issues (proxy)')\n",
    "plt.xlabel('avg_daily_hours')\n",
    "plt.ylabel('sleep_issues (1–5)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #5: Screen Time vs Mental Wellness Survey\n",
    "\n",
    "**Official dataset page:** `https://www.kaggle.com/datasets/adharshinikumar/screentime-vs-mentalwellness-survey-2025`\n",
    "\n",
    "**Download method:** Through Kaggle (login and terms acceptance required)\n",
    "\n",
    "**Description**\n",
    "The Screen Time vs Mental Wellness Survey dataset is based on self-reported survey responses examining how leisure screen time exposure relates to mental health outcomes. Participants reported their daily screen time in leisure activities like social media, gaming, streaming, along with indicators such as stress levels, sleep-related outcomes, and general mental wellness. The dataset is designed to explore whether higher screen exposure is associated with poorer mental wellbeing rather than focusing on specific platforms or interaction styles.\n",
    "\n",
    "Because all responses are collected at a single point in time, this dataset supports correlational analysis only. While we can observe patterns such as higher reported leisure screen time being associated with increased stress or reduced sleep quality, we cannot establish causal direction. For this project, Dataset 5 is used primarily as a supporting validation dataset, helping determine whether general screen exposure aligns with trends observed in social-media-specific analysis.\n",
    "\n",
    "Important metrics include leisure screen time, sleep duration and quality, stress level, and an overall mental wellbeing score capturing mood, energy, and focus. Together, these variables allow us to examine whether overall screen exposure, regardless of usage type, is meaningfully related to adult mental wellbeing and whether digital exposure has any measurable associaton with wellbeing in the first place.\n",
    "\n",
    "However, several potential biases must be considered. This dataset includes respondents aged 16-60, which requires some removal to align with out 18+ age demographics. Gender differences may also influence reported sleep, stress, and wellbeing and should be considered when interpreting results. Additionally, all measures are self-reported. This may introduce biases such as underreporting screen time or misjudging stress, sleep quality, and mental wellbeing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_5 = pd.read_csv(\"data/00-raw/ScreenTime vs MentalWellness.csv\")\n",
    "dataset_5.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loads correctly but includes unnecessary column\n",
    "\n",
    "Remove empty column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = dataset_5.loc[:, ~dataset_5.columns.str.contains(\"^Unnamed\")]\n",
    "# Drops empty column and keeps only meaningful survey variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count missing values in the dataset to be cleared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5.isnull().any()\n",
    "# No missing values to be handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove respondents under 18 to align with study demographics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = dataset_5[dataset_5[\"age\"] >= 18]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for value limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5.describe()\n",
    "# All data has correct min and max values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming columns for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = dataset_5.rename(columns={\n",
    "    \"leisure_screen_hours\": \"Leisure Screen Time\",\n",
    "    \"sleep_hours\": \"Sleep Hours\",\n",
    "    \"sleep_quality_1_5\": \"Sleep Quality\",\n",
    "    \"stress_level_0_10\": \"Stress Level\",\n",
    "    \"mental_wellness_index_0_100\": \"Mental Wellness Index\"\n",
    "})\n",
    "# Improves readability without modifying any values, only labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetting index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5 = dataset_5.reset_index(drop=True)\n",
    "# This ensures clean sequential indexing after filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save processed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5.to_csv(\n",
    "    \"data/02-processed/ScreenTime_vs_MentalWellness_processed.csv\",\n",
    "    index=False\n",
    ")\n",
    "dataset_5.shape\n",
    "# Dataset is now clean and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> This project uses secondary data from publicly available sources such as Kaggle. While we do not collect data directly from participants, there is a risk that individuals did not anticipate all future uses of their data. We mitigate this by using the data only for aggregate research purposes and avoiding sensitive individual-level conclusions.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Social media wellbeing datasets often overrepresent younger, more active users or specific regions, which may bias results. If ignored, this could lead to misleading conclusions about broader populations. We will report these limitations and avoid generalizing beyond the sampled groups.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> The datasets we use are de-identified, but indirect identification is still possible from detailed demographics or behavior. To reduce risk, we will drop unnecessary fields, avoid small subgroup reporting, and present only aggregated results.\n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> If demographic variables are available, we will use them to test whether associations differ across groups (ex: gender, age ranges) and report any differences. We will be careful not to interpret group differences as biological or moral claims, and we will highlight dataset limitations.\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> Data will be stored in secure, course-approved environments with access limited to project members. Although the data are public and anonymized, restricting access reduces unnecessary exposure.\n",
    "\n",
    " - [] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> Not directly applicable because we are using public, de-identified secondary datasets and do not control data collection. If any dataset includes removals or takedown procedures, we will follow the dataset’s terms and avoid downloading unnecessary copies.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> We will keep datasets only for the course project duration and delete local copies afterward. Keeping fewer copies reduces exposure risk and supports responsible data handling.\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Wellbeing and social media experience vary by culture, age, and context, and the dataset may not capture these differences. We will interpret results cautiously and avoid universal claims, using prior literature to contextualize findings.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> We will look for bias in the dataset, like missing data, uneven group sizes, or important factors that aren’t included. We will report these issues and control for key variables when possible, instead of acting like the results are causal.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We will avoid misleading visuals and cherry-picking. We will report effect sizes with uncertainty and include null results when they occur.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> We will not display or publish any PPI data. Results will be reported only in aggregated form, and we will avoid subgroup breakdowns that could enable re-identification.\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> We will document data cleaning and analysis steps and keep code organized so results can be reproduced. This supports accountability if errors or ethical concerns are found later.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> We will avoid using variables that can “stand in” for protected traits (like race or income) in a way that could be unfair. If we include those variables as controls, we will explain why and be careful how we interpret them.\n",
    "\n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    "> We will check whether results look different across demographic groups (when that data is available). If we build a prediction model, we will also compare error rates across groups and report any big gaps.\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> We will choose evaluation metrics that match the task and report multiple metrics where relevant. We will avoid optimizing a single metric that could hide subgroup harms.\n",
    "\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "\n",
    "> We will use simple models like regression so it’s clear why the model gives a result. We will explain the main factors and what they mean in plain language.\n",
    "\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We will explain our findings in plain language and note what the model cannot conclude. We will highlight bias and missing factors and keep conclusions within what the data supports.\n",
    "\n",
    "### E. Deployment\n",
    " - [] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> Not applicable because we are not deploying a model or system. This is a course project analysis only.\n",
    "\n",
    " - [] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> Not applicable because our results will not be used to make decisions about individuals. If we find something misleading or harmful, we will revise the analysis and how we report it.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " \n",
    "> Not applicable because there is no production deployment. If issues are found, we can update or remove the analysis/report.\n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    " \n",
    "> People could misuse our results to say social media is always good or always bad, or to shame people with mental health issues. We will reduce this risk by saying our findings are correlational, clearly listing limits, and keeping conclusions only within what the data supports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Team Expectation 1: Communication and Availability*\n",
    "- Communications will be done through Discord and iMessage as they are the most readily available, and all authors are well-versed in both applications.\n",
    "- Team members are expected to respond to messages within 48 hours unless there was prior communication that they may be unavailable for personal reasons.\n",
    "- If a meeting needs to be scheduled, all team members must free up some of their time at least one day out of any given week to discuss proposals and findings live with other members. Discord will be used to communicate for meetings.\n",
    "\n",
    "### *Team Expectation 2: Tone and Respectful Interactions*\n",
    "- All communication should be respectful, constructive, and professional.\n",
    "- As stated in the COGS108 Team Policies, direct but polite is the agreed upon tone.\n",
    "- Team members will assume good intentions and view given criticism as a way to improve the work done rather than a personal attack.\n",
    "\n",
    "### *Team Expectation 3: Decision making*\n",
    "- Unless in a time crunch with a team member not responding, all decisions should be made through the agreement of all members of the team.\n",
    "- If all members can not come to a consensus, a majority vote will be used to make decisions.\n",
    "- Major decisions that can change deadlines or project direction must be made early to avoid time crunch. They also must be communicated clearly to all members of the team.\n",
    "\n",
    "### *Team Expectation 4: Task assignment and accountability*\n",
    "- Tasks will be assigned both voluntarily and based on each member's strengths.\n",
    "- Although team members may be more involved in specific tasks than others, we will ensure equal overall effort across the entire project.\n",
    "- Each set task will have an expected deadline and a section “manager”, who will be the owner mainly responsible for that task.\n",
    "\n",
    "### *Team Expectation 5: Deadlines and Task support*\n",
    "- All team members are expected to meet the agreed upon deadlines.\n",
    "- If someone believes that they may not be able to meet a given deadline, a notification to the rest of the members is expected as soon as possible, preferably 48 to 72 hours in advance of the deadline.\n",
    "- If a team member is struggling to work on a certain part of the project, the team will meet together to redistribute tasks that better support the members strengths and weaknesses.\n",
    "\n",
    "### *Team Expectation 6: Conflict Resolution*\n",
    "- Conflicts will be addressed directly but respectfully.\n",
    "- Conflicts will be addressed early to not halt task completion or team morale.\n",
    "- Open discussion during a meeting or live communication through messaging apps will be used to resolve conflicts.\n",
    "- If a conflict does not get resolved in a respectful manner through team members, seeking out to the professor will be the immediate next step.\n",
    "\n",
    "### *Team Expectation 7: Handling Non-Participation*\n",
    "- In the event that a team member is constantly unresponsive or fails to complete an assigned task, the rest of the team will do as follows:\n",
    "  - Contact the member directly through both Discord and iMessage clearly outlining expectations for improvement, within a reasonable time period, in a respectful manner.\n",
    "  - If no improvement occurs within the given reasonable time period, the professor will be notified by the other team members about the situation.\n",
    "\n",
    "### *Team Expectation 8: Team agreement to policies*\n",
    "- By participating in this project and submitting this proposal, each team member confirms that they have:\n",
    "  - Read the COGS108 Team Policies\n",
    "  - Agreed to the expectations listed above\n",
    "  - Committed to contributing fairly, communicating openly, and working collaboratively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal (Updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Discussion Date | Discussion Time & Place | Completed Before Discussion | What to Discuss |\n",
    "|---|---|---|---|\n",
    "| 2/4 | Discord - throughout day | Edit, finalize, and submit proposal | Confirm datasets to use; discuss task assignment and edit timeline accordingly; outline planned wrangling and analysis approach |\n",
    "| 2/17 | Discord - throughout day | Complete Dataset #1 and #4 wrangling; write data descriptions and overview | Review wrangling outputs and cleaning decisions; finalize Data Checkpoint submission |\n",
    "| 2/24 | Discord - throughout day | Begin EDA on cleaned datasets; draft initial visualizations | Review EDA progress; identify key patterns; refine analysis plan for EDA Checkpoint |\n",
    "| 3/3 | Discord - throughout day | Finalize EDA; begin regression/association analysis | Discuss/edit EDA Checkpoint; confirm modeling approach and variable choices |\n",
    "| 3/13 | Discord - throughout day | Complete analysis; draft results/conclusion/discussion sections | Discuss/edit full project; assign final writing and review tasks |\n",
    "| 3/18 | Before 11:59 PM | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
